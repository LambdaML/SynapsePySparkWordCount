{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 104 - Train, Test, Evaluate for Regression with Auto Imports Dataset\n",
        "\n",
        "This sample notebook is based on the Gallery [Sample 6: Train, Test, Evaluate\n",
        "for Regression: Auto Imports\n",
        "Dataset](https://gallery.cortanaintelligence.com/Experiment/670fbfc40c4f44438bfe72e47432ae7a)\n",
        "for AzureML Studio.  This experiment demonstrates how to build a regression\n",
        "model to predict the automobile's price.  The process includes training, testing,\n",
        "and evaluating the model on the Automobile Imports data set.\n",
        "\n",
        "This sample demonstrates the use of several members of the mmlspark library:\n",
        "- [`TrainRegressor`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/TrainRegressor.html)\n",
        "- [`SummarizeData`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/SummarizeData.html)\n",
        "- [`CleanMissingData`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/CleanMissingData.html)\n",
        "- [`ComputeStatistics`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/ComputeStatistics.html)\n",
        "- [`FindBestModel`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/FindBestModel.html)\n",
        "\n",
        "First, import the pandas package so that we can read and parse the datafile\n",
        "using `pandas.read_csv()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1537651Z",
              "execution_start_time": "2021-03-15T08:42:12.2635326Z",
              "execution_finish_time": "2021-03-15T08:42:16.3957448Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "data = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/AutomobilePriceRaw.parquet\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To learn more about the data that was just read into the DataFrame,\n",
        "summarize the data using `SummarizeData` and print the summary.  For each\n",
        "column of the DataFrame, `SummarizeData` will report the summary statistics\n",
        "in the following subcategories for each column:\n",
        "* Feature name\n",
        "* Counts\n",
        "  - Count\n",
        "  - Unique Value Count\n",
        "  - Missing Value Count\n",
        "* Quantiles\n",
        "  - Min\n",
        "  - 1st Quartile\n",
        "  - Median\n",
        "  - 3rd Quartile\n",
        "  - Max\n",
        "* Sample Statistics\n",
        "  - Sample Variance\n",
        "  - Sample Standard Deviation\n",
        "  - Sample Skewness\n",
        "  - Sample Kurtosis\n",
        "* Percentiles\n",
        "  - P0.5\n",
        "  - P1\n",
        "  - P5\n",
        "  - P95\n",
        "  - P99\n",
        "  - P99.5\n",
        "\n",
        "Note that several columns have missing values (`normalized-losses`, `bore`,\n",
        "`stroke`, `horsepower`, `peak-rpm`, `price`).  This summary can be very\n",
        "useful during the initial phases of data discovery and characterization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.15532Z",
              "execution_start_time": "2021-03-15T08:42:16.4883718Z",
              "execution_finish_time": "2021-03-15T08:42:47.8046248Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "              Feature  Count  Unique_Value_Count  ...       P95      P99     P99_5\n0           symboling  205.0                 6.0  ...      3.00      3.0      3.00\n1   normalized-losses  164.0                53.0  ...    188.00    231.0    256.00\n2                make  205.0                22.0  ...       NaN      NaN       NaN\n3           fuel-type  205.0                 2.0  ...       NaN      NaN       NaN\n4          aspiration  205.0                 2.0  ...       NaN      NaN       NaN\n5          body-style  205.0                 5.0  ...       NaN      NaN       NaN\n6        drive-wheels  205.0                 3.0  ...       NaN      NaN       NaN\n7     engine-location  205.0                 2.0  ...       NaN      NaN       NaN\n8          wheel-base  205.0                53.0  ...    110.00    115.6    115.60\n9              length  205.0                75.0  ...    197.00    202.6    202.60\n10              width  205.0                45.0  ...     70.50     71.7     72.00\n11             height  205.0                50.0  ...     57.50     59.1     59.80\n12        curb-weight  205.0               166.0  ...   3505.00   3950.0   4066.00\n13        engine-type  205.0                 7.0  ...       NaN      NaN       NaN\n14   num-of-cylinders  205.0                 7.0  ...       NaN      NaN       NaN\n15        engine-size  205.0                46.0  ...    203.00    304.0    308.00\n16        fuel-system  205.0                 8.0  ...       NaN      NaN       NaN\n17               bore  201.0                39.0  ...      3.78      3.8      3.94\n18             stroke  201.0                37.0  ...      3.64      3.9      4.17\n19  compression-ratio  205.0                32.0  ...     21.90     23.0     23.00\n20         horsepower  203.0                57.0  ...    182.00    207.0    262.00\n21           peak-rpm  203.0                25.0  ...   6000.00   6000.0   6600.00\n22           city-mpg  205.0                30.0  ...     37.00     45.0     47.00\n23        highway-mpg  205.0                31.0  ...     43.00     50.0     53.00\n24              price  201.0               189.0  ...  32528.00  40960.0  41315.00\n\n[25 rows x 19 columns]"
          },
          "execution_count": 2,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.stages import SummarizeData\n",
        "summary = SummarizeData().transform(data)\n",
        "summary.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the dataset into train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1565633Z",
              "execution_start_time": "2021-03-15T08:42:47.8968367Z",
              "execution_finish_time": "2021-03-15T08:42:49.9741107Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   symboling  normalized-losses        make  ... city-mpg highway-mpg    price\n0         -1              137.0  mitsubishi  ...       23          30   9279.0\n1          0              108.0      nissan  ...       17          22  14399.0\n2          0              128.0      nissan  ...       17          22  13499.0\n3          0              161.0      peugot  ...       19          24  11900.0\n4          1              103.0      nissan  ...       31          37   7349.0\n5          1              122.0      nissan  ...       31          37   6849.0\n6          1              125.0  mitsubishi  ...       25          32   6989.0\n7          1              125.0  mitsubishi  ...       25          32   8189.0\n8          1              125.0  mitsubishi  ...       23          30   9279.0\n9          1              128.0      nissan  ...       45          50   7099.0\n\n[10 rows x 25 columns]"
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# split the data into training and testing datasets\n",
        "train, test = data.randomSplit([0.6, 0.4], seed=123)\n",
        "train.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now use the `CleanMissingData` API to replace the missing values in the\n",
        "dataset with something more useful or meaningful.  Specify a list of columns\n",
        "to be cleaned, and specify the corresponding output column names, which are\n",
        "not required to be the same as the input column names. `CleanMissiongData`\n",
        "offers the options of \"Mean\", \"Median\", or \"Custom\" for the replacement\n",
        "value.  In the case of \"Custom\" value, the user also specifies the value to\n",
        "use via the \"customValue\" parameter.  In this example, we will replace\n",
        "missing values in numeric columns with the median value for the column.  We\n",
        "will define the model here, then use it as a Pipeline stage when we train our\n",
        "regression models and make our predictions in the following steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1579493Z",
              "execution_start_time": "2021-03-15T08:42:50.0726051Z",
              "execution_finish_time": "2021-03-15T08:42:52.1314451Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.featurize import CleanMissingData\n",
        "cols = [\"normalized-losses\", \"stroke\", \"bore\", \"horsepower\",\n",
        "        \"peak-rpm\", \"price\"]\n",
        "cleanModel = CleanMissingData().setCleaningMode(\"Median\") \\\n",
        "                               .setInputCols(cols).setOutputCols(cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will create two Regressor models for comparison: Poisson Regression\n",
        "and Random Forest.  PySpark has several regressors implemented:\n",
        "* `LinearRegression`\n",
        "* `IsotonicRegression`\n",
        "* `DecisionTreeRegressor`\n",
        "* `RandomForestRegressor`\n",
        "* `GBTRegressor` (Gradient-Boosted Trees)\n",
        "* `AFTSurvivalRegression` (Accelerated Failure Time Model Survival)\n",
        "* `GeneralizedLinearRegression` -- fit a generalized model by giving symbolic\n",
        "  description of the linear preditor (link function) and a description of the\n",
        "  error distribution (family).  The following families are supported:\n",
        "  - `Gaussian`\n",
        "  - `Binomial`\n",
        "  - `Poisson`\n",
        "  - `Gamma`\n",
        "  - `Tweedie` -- power link function specified through `linkPower`\n",
        "Refer to the\n",
        "[Pyspark API Documentation](http://spark.apache.org/docs/latest/api/python/)\n",
        "for more details.\n",
        "\n",
        "`TrainRegressor` creates a model based on the regressor and other parameters\n",
        "that are supplied to it, then trains data on the model.\n",
        "\n",
        "In this next step, Create a Poisson Regression model using the\n",
        "`GeneralizedLinearRegressor` API from Spark and create a Pipeline using the\n",
        "`CleanMissingData` and `TrainRegressor` as pipeline stages to create and\n",
        "train the model.  Note that because `TrainRegressor` expects a `labelCol` to\n",
        "be set, there is no need to set `linkPredictionCol` when setting up the\n",
        "`GeneralizedLinearRegressor`.  Fitting the pipe on the training dataset will\n",
        "train the model.  Applying the `transform()` of the pipe to the test dataset\n",
        "creates the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1592362Z",
              "execution_start_time": "2021-03-15T08:42:52.2248027Z",
              "execution_finish_time": "2021-03-15T08:43:00.4920271Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 5,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# train Poisson Regression Model\n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from mmlspark.train import TrainRegressor\n",
        "\n",
        "glr = GeneralizedLinearRegression(family=\"poisson\", link=\"log\")\n",
        "poissonModel = TrainRegressor().setModel(glr).setLabelCol(\"price\").setNumFeatures(256)\n",
        "poissonPipe = Pipeline(stages = [cleanModel, poissonModel]).fit(train)\n",
        "poissonPrediction = poissonPipe.transform(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, repeat these steps to create a Random Forest Regression model using the\n",
        "`RandomRorestRegressor` API from Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1606651Z",
              "execution_start_time": "2021-03-15T08:43:00.5873049Z",
              "execution_finish_time": "2021-03-15T08:43:06.7654002Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 6,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# train Random Forest regression on the same training data:\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "rfr = RandomForestRegressor(maxDepth=30, maxBins=128, numTrees=8, minInstancesPerNode=1)\n",
        "randomForestModel = TrainRegressor(model=rfr, labelCol=\"price\", numFeatures=256).fit(train)\n",
        "randomForestPipe = Pipeline(stages = [cleanModel, randomForestModel]).fit(train)\n",
        "randomForestPrediction = randomForestPipe.transform(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the models have been trained and scored, compute some basic statistics\n",
        "to evaluate the predictions.  The following statistics are calculated for\n",
        "regression models to evaluate:\n",
        "* Mean squared error\n",
        "* Root mean squared error\n",
        "* R^2\n",
        "* Mean absolute error\n",
        "\n",
        "Use the `ComputeModelStatistics` API to compute basic statistics for\n",
        "the Poisson and the Random Forest models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1620727Z",
              "execution_start_time": "2021-03-15T08:43:06.860526Z",
              "execution_finish_time": "2021-03-15T08:43:08.932666Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Poisson Metrics\n   mean_squared_error  root_mean_squared_error       R^2  mean_absolute_error\n0        6.387382e+06              2527.326961  0.856324          1617.131942"
          },
          "execution_count": 7,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputeModelStatistics\n",
        "poissonMetrics = ComputeModelStatistics().transform(poissonPrediction)\n",
        "print(\"Poisson Metrics\")\n",
        "poissonMetrics.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1635305Z",
              "execution_start_time": "2021-03-15T08:43:09.0300707Z",
              "execution_finish_time": "2021-03-15T08:43:11.115044Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Random Forest Metrics\n   mean_squared_error  root_mean_squared_error       R^2  mean_absolute_error\n0        1.144745e+07              3383.408586  0.742503          2038.477109"
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "randomForestMetrics = ComputeModelStatistics().transform(randomForestPrediction)\n",
        "print(\"Random Forest Metrics\")\n",
        "randomForestMetrics.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also compute per instance statistics for `poissonPrediction`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1648815Z",
              "execution_start_time": "2021-03-15T08:43:11.2045647Z",
              "execution_finish_time": "2021-03-15T08:43:13.2735881Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     price        Scores      L1_loss       L2_loss\n0   8949.0   7908.261962  1040.738038  1.083136e+06\n1   9549.0   8676.384389   872.615611  7.614580e+05\n2  13499.0  14587.748803  1088.748803  1.185374e+06\n3   7999.0   6433.316004  1565.683996  2.451366e+06\n4   7499.0   6722.115545   776.884455  6.035495e+05\n5   7799.0   6355.008858  1443.991142  2.085110e+06\n6   5499.0   6487.236219   988.236219  9.766108e+05\n7   6649.0   6575.215170    73.784830  5.444201e+03\n8   8249.0   6911.996479  1337.003521  1.787578e+06\n9  14489.0  13400.356342  1088.643658  1.185145e+06"
          },
          "execution_count": 9,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputePerInstanceStatistics\n",
        "def demonstrateEvalPerInstance(pred):\n",
        "    return ComputePerInstanceStatistics().transform(pred) \\\n",
        "               .select(\"price\", \"Scores\", \"L1_loss\", \"L2_loss\") \\\n",
        "               .limit(10).toPandas()\n",
        "demonstrateEvalPerInstance(poissonPrediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and with `randomForestPrediction`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1664553Z",
              "execution_start_time": "2021-03-15T08:43:13.3725781Z",
              "execution_finish_time": "2021-03-15T08:43:15.4350505Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     price      Scores     L1_loss       L2_loss\n0   6669.0   6457.2500    211.7500  4.483806e+04\n1   8499.0   8073.3125    425.6875  1.812098e+05\n2   9959.0  10710.0625    751.0625  5.640949e+05\n3   8921.0   9949.3750   1028.3750  1.057555e+06\n4  10595.0  19871.3750   9276.3750  8.605113e+07\n5  12764.0  15938.2500   3174.2500  1.007586e+07\n6  37028.0  17058.3125  19969.6875  3.987884e+08\n7   7295.0   7128.3750    166.6250  2.776389e+04\n8   5399.0   6384.2500    985.2500  9.707176e+05\n9   7129.0   6624.0000    505.0000  2.550250e+05"
          },
          "execution_count": 10,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "demonstrateEvalPerInstance(randomForestPrediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 42,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:41:23.1680292Z",
              "execution_start_time": "2021-03-15T08:43:15.5386417Z",
              "execution_finish_time": "2021-03-15T08:43:19.6611249Z"
            },
            "text/plain": "StatementMeta(SamplePool, 42, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 11,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}