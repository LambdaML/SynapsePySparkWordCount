{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Deployment with Spark Serving \n",
        "In this example, we try to predict incomes from the *Adult Census* dataset. Then we will use Spark serving to deploy it as a realtime web service. \n",
        "First, we import needed packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.8926772Z",
              "execution_start_time": "2021-03-14T16:09:51.671014Z",
              "execution_finish_time": "2021-03-14T16:09:53.7285222Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's read the data and split it to train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.8943199Z",
              "execution_start_time": "2021-03-14T16:09:53.8230914Z",
              "execution_finish_time": "2021-03-14T16:10:04.2442115Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "  education       marital-status  hours-per-week  income\n0      10th             Divorced            25.0   <=50K\n1      10th             Divorced            40.0   <=50K\n2      10th             Divorced            40.0   <=50K\n3      10th             Divorced            40.0   <=50K\n4      10th   Married-civ-spouse            16.0   <=50K\n5      10th   Married-civ-spouse            35.0   <=50K\n6      10th   Married-civ-spouse            40.0   <=50K\n7      10th   Married-civ-spouse            40.0   <=50K\n8      10th   Married-civ-spouse            40.0   <=50K\n9      10th   Married-civ-spouse            40.0   <=50K"
          },
          "execution_count": 2,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "data = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/AdultCensusIncome.parquet\")\n",
        "data = data.select([\"education\", \"marital-status\", \"hours-per-week\", \"income\"])\n",
        "train, test = data.randomSplit([0.75, 0.25], seed=123)\n",
        "train.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`TrainClassifier` can be used to initialize and fit a model, it wraps SparkML classifiers.\n",
        "You can use `help(mmlspark.TrainClassifier)` to view the different parameters.\n",
        "\n",
        "Note that it implicitly converts the data into the format expected by the algorithm. More specifically it:\n",
        " tokenizes, hashes strings, one-hot encodes categorical variables, assembles the features into a vector\n",
        "etc.  The parameter `numFeatures` controls the number of hashed features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.8962127Z",
              "execution_start_time": "2021-03-14T16:10:04.3479112Z",
              "execution_finish_time": "2021-03-14T16:10:20.8886619Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import TrainClassifier\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "model = TrainClassifier(model=LogisticRegression(), labelCol=\"income\", numFeatures=256).fit(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the model is trained, we score it against the test dataset and view metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.8978746Z",
              "execution_start_time": "2021-03-14T16:10:20.985616Z",
              "execution_finish_time": "2021-03-14T16:10:23.1140408Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "root\n |-- education: string (nullable = true)\n |-- marital-status: string (nullable = true)\n |-- hours-per-week: double (nullable = true)\n |-- income: string (nullable = true)\n |-- scores: vector (nullable = true)\n |-- scored_probabilities: vector (nullable = true)\n |-- scored_labels: double (nullable = false)"
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputeModelStatistics, TrainedClassifierModel\n",
        "prediction = model.transform(test)\n",
        "prediction.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.9002621Z",
              "execution_start_time": "2021-03-14T16:10:23.229193Z",
              "execution_finish_time": "2021-03-14T16:10:27.353423Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "  evaluation_type  ...       AUC\n0  Classification  ...  0.865245\n\n[1 rows x 6 columns]\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2110: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  Unsupported type in conversion to Arrow: MatrixUDT\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n  warnings.warn(msg)"
          },
          "execution_count": 5,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "metrics = ComputeModelStatistics().transform(prediction)\n",
        "metrics.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we will define the webservice input/output.\n",
        "For more information, you can visit the [documentation for Spark Serving](https://github.com/Azure/mmlspark/blob/master/docs/mmlspark-serving.md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.9278825Z",
              "execution_start_time": "2021-03-14T16:10:27.4519269Z",
              "execution_finish_time": "2021-03-14T16:10:29.5154862Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 6,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from pyspark.sql.types import *\n",
        "from mmlspark.io import *\n",
        "import uuid\n",
        "\n",
        "serving_inputs = spark.readStream.server() \\\n",
        "    .address(\"localhost\", 8898, \"my_api\") \\\n",
        "    .option(\"name\", \"my_api\") \\\n",
        "    .load() \\\n",
        "    .parseRequest(\"my_api\", test.schema)\n",
        "\n",
        "serving_outputs = model.transform(serving_inputs) \\\n",
        "  .makeReply(\"scored_labels\")\n",
        "\n",
        "server = serving_outputs.writeStream \\\n",
        "    .server() \\\n",
        "    .replyTo(\"my_api\") \\\n",
        "    .queryName(\"my_query\") \\\n",
        "    .option(\"checkpointLocation\", \"file:///tmp/checkpoints-{}\".format(uuid.uuid1())) \\\n",
        "    .start()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the webservice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.9294089Z",
              "execution_start_time": "2021-03-14T16:10:29.6136919Z",
              "execution_finish_time": "2021-03-14T16:10:33.7534679Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Response {\"scored_labels\":0.0}"
          },
          "execution_count": 7,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import requests\n",
        "data = u'{\"education\":\" 10th\",\"marital-status\":\"Divorced\",\"hours-per-week\":40.0}'\n",
        "r = requests.post(data=data, url=\"http://localhost:8898/my_api\")\n",
        "print(\"Response {}\".format(r.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.9307925Z",
              "execution_start_time": "2021-03-14T16:10:33.8608174Z",
              "execution_finish_time": "2021-03-14T16:10:37.9846979Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Response {\"scored_labels\":1.0}"
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import requests\n",
        "data = u'{\"education\":\" Masters\",\"marital-status\":\"Married-civ-spouse\",\"hours-per-week\":40.0}'\n",
        "r = requests.post(data=data, url=\"http://localhost:8898/my_api\")\n",
        "print(\"Response {}\".format(r.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.9323714Z",
              "execution_start_time": "2021-03-14T16:10:38.0865102Z",
              "execution_finish_time": "2021-03-14T16:10:58.75361Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 9,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import time\n",
        "time.sleep(20) # wait for server to finish setting up (just to be safe)\n",
        "server.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 23,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-14T16:09:22.9336772Z",
              "execution_start_time": "2021-03-14T16:10:58.8560897Z",
              "execution_finish_time": "2021-03-14T16:11:00.9230108Z"
            },
            "text/plain": "StatementMeta(SamplePool, 23, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 10,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}