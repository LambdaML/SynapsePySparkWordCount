{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 105 - Training Regressions\n",
        "\n",
        "This example notebook is similar to\n",
        "[Notebook 102](102 - Regression Example with Flight Delay Dataset.ipynb).\n",
        "In this example, we will demonstrate the use of `DataConversion()` in two\n",
        "ways.  First, to convert the data type of several columns after the dataset\n",
        "has been read in to the Spark DataFrame instead of specifying the data types\n",
        "as the file is read in.  Second, to convert columns to categorical columns\n",
        "instead of iterating over the columns and applying the `StringIndexer`.\n",
        "\n",
        "This sample demonstrates how to use the following APIs:\n",
        "- [`TrainRegressor`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/TrainRegressor.html)\n",
        "- [`ComputePerInstanceStatistics`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/ComputePerInstanceStatistics.html)\n",
        "- [`DataConversion`\n",
        "  ](http://mmlspark.azureedge.net/docs/pyspark/DataConversion.html)\n",
        "\n",
        "First, import the pandas package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6219883Z",
              "execution_start_time": "2021-03-15T08:40:04.5386721Z",
              "execution_finish_time": "2021-03-15T08:40:06.6098622Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, import the CSV dataset: retrieve the file if needed, save it locally,\n",
        "read the data into a pandas dataframe via `read_csv()`, then convert it to\n",
        "a Spark dataframe.\n",
        "\n",
        "Print the schema of the dataframe, and note the columns that are `long`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6233927Z",
              "execution_start_time": "2021-03-15T08:40:06.7127497Z",
              "execution_finish_time": "2021-03-15T08:40:17.0477187Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "records read: 490199\nSchema: \nroot\n |-- Quarter: long (nullable = true)\n |-- Month: long (nullable = true)\n |-- DayofMonth: long (nullable = true)\n |-- DayOfWeek: long (nullable = true)\n |-- Carrier: string (nullable = true)\n |-- OriginAirportID: long (nullable = true)\n |-- DestAirportID: long (nullable = true)\n |-- CRSDepTime: long (nullable = true)\n |-- DepTimeBlk: string (nullable = true)\n |-- CRSArrTime: long (nullable = true)\n |-- ArrDelay: double (nullable = true)\n |-- ArrTimeBlk: string (nullable = true)\n |-- Diverted: double (nullable = true)\n\n   Quarter  Month  DayofMonth  ...  ArrDelay ArrTimeBlk  Diverted\n0        3      9           9  ...      17.0  2100-2159       0.0\n1        3      9          23  ...     159.0  2100-2159       0.0\n2        3      9          24  ...       8.0  2100-2159       0.0\n3        3      9          18  ...      32.0  2100-2159       0.0\n4        3      9          16  ...       NaN  2100-2159       0.0\n5        3      9          13  ...       5.0  2100-2159       0.0\n6        3      9          14  ...       1.0  2100-2159       0.0\n7        3      9          12  ...      64.0  2100-2159       0.0\n8        3      9          10  ...      48.0  2100-2159       0.0\n9        3      9          11  ...       9.0  2100-2159       0.0\n\n[10 rows x 13 columns]"
          },
          "execution_count": 2,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "flightDelay = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/On_Time_Performance_2012_9.parquet\")\n",
        "# print some basic info\n",
        "print(\"records read: \" + str(flightDelay.count()))\n",
        "print(\"Schema: \")\n",
        "flightDelay.printSchema()\n",
        "flightDelay.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the `DataConversion` transform API to convert the columns listed to\n",
        "double.\n",
        "\n",
        "The `DataConversion` API accepts the following types for the `convertTo`\n",
        "parameter:\n",
        "* `boolean`\n",
        "* `byte`\n",
        "* `short`\n",
        "* `integer`\n",
        "* `long`\n",
        "* `float`\n",
        "* `double`\n",
        "* `string`\n",
        "* `toCategorical`\n",
        "* `clearCategorical`\n",
        "* `date` -- converts a string or long to a date of the format\n",
        "  \"yyyy-MM-dd HH:mm:ss\" unless another format is specified by\n",
        "the `dateTimeFormat` parameter.\n",
        "\n",
        "Again, print the schema and note that the columns are now `double`\n",
        "instead of long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6249269Z",
              "execution_start_time": "2021-03-15T08:40:17.1435495Z",
              "execution_finish_time": "2021-03-15T08:40:19.2021008Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "root\n |-- Quarter: double (nullable = true)\n |-- Month: double (nullable = true)\n |-- DayofMonth: double (nullable = true)\n |-- DayOfWeek: double (nullable = true)\n |-- Carrier: string (nullable = true)\n |-- OriginAirportID: double (nullable = true)\n |-- DestAirportID: double (nullable = true)\n |-- CRSDepTime: double (nullable = true)\n |-- DepTimeBlk: string (nullable = true)\n |-- CRSArrTime: double (nullable = true)\n |-- ArrDelay: double (nullable = true)\n |-- ArrTimeBlk: string (nullable = true)\n |-- Diverted: double (nullable = true)\n\n   Quarter  Month  DayofMonth  ...  ArrDelay ArrTimeBlk  Diverted\n0      3.0    9.0        14.0  ...      -6.0  2000-2059       0.0\n1      3.0    9.0        14.0  ...     -17.0  1500-1559       0.0\n2      3.0    9.0        14.0  ...     -22.0  1300-1359       0.0\n3      3.0    9.0        14.0  ...      -7.0  2100-2159       0.0\n4      3.0    9.0        14.0  ...     -13.0  1300-1359       0.0\n5      3.0    9.0        14.0  ...      21.0  1400-1459       0.0\n6      3.0    9.0        14.0  ...     -14.0  1100-1159       0.0\n7      3.0    9.0        14.0  ...      -2.0  1500-1559       0.0\n8      3.0    9.0        14.0  ...      -8.0  1200-1259       0.0\n9      3.0    9.0        14.0  ...       5.0  2200-2259       0.0\n\n[10 rows x 13 columns]"
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.featurize import DataConversion\n",
        "flightDelay = DataConversion(cols=[\"Quarter\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\n",
        "                                   \"OriginAirportID\",\"DestAirportID\",\n",
        "                                   \"CRSDepTime\",\"CRSArrTime\"],\n",
        "                             convertTo=\"double\") \\\n",
        "                  .transform(flightDelay)\n",
        "flightDelay.printSchema()\n",
        "flightDelay.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the datasest into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6263275Z",
              "execution_start_time": "2021-03-15T08:40:19.294716Z",
              "execution_finish_time": "2021-03-15T08:40:21.3506619Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "train, test = flightDelay.randomSplit([0.75, 0.25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a regressor model and train it on the dataset.\n",
        "\n",
        "First, use `DataConversion` to convert the columns `Carrier`, `DepTimeBlk`,\n",
        "and `ArrTimeBlk` to categorical data.  Recall that in Notebook 102, this\n",
        "was accomplished by iterating over the columns and converting the strings\n",
        "to index values using the `StringIndexer` API.  The `DataConversion` API\n",
        "simplifies the task by allowing you to specify all columns that will have\n",
        "the same end type in a single command.\n",
        "\n",
        "Create a LinearRegression model using the Limited-memory BFGS solver\n",
        "(`l-bfgs`), an `ElasticNet` mixing parameter of `0.3`, and a `Regularization`\n",
        "of `0.1`.\n",
        "\n",
        "Train the model with the `TrainRegressor` API fit on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6277016Z",
              "execution_start_time": "2021-03-15T08:40:21.4493452Z",
              "execution_finish_time": "2021-03-15T08:40:54.9024654Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 5,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import TrainRegressor, TrainedRegressorModel\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "trainCat = DataConversion(cols=[\"Carrier\",\"DepTimeBlk\",\"ArrTimeBlk\"],\n",
        "                          convertTo=\"toCategorical\") \\\n",
        "               .transform(train)\n",
        "testCat  = DataConversion(cols=[\"Carrier\",\"DepTimeBlk\",\"ArrTimeBlk\"],\n",
        "                          convertTo=\"toCategorical\") \\\n",
        "               .transform(test)\n",
        "lr = LinearRegression().setSolver(\"l-bfgs\").setRegParam(0.1) \\\n",
        "                       .setElasticNetParam(0.3)\n",
        "model = TrainRegressor(model=lr, labelCol=\"ArrDelay\").fit(trainCat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Score the regressor on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.629181Z",
              "execution_start_time": "2021-03-15T08:40:55.0000079Z",
              "execution_finish_time": "2021-03-15T08:40:57.0731685Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Quarter  Month  DayofMonth  ...  ArrTimeBlk  Diverted    scores\n0      3.0    9.0         1.0  ...          10       0.0  3.970542\n1      3.0    9.0         1.0  ...           2       0.0 -2.703046\n2      3.0    9.0         1.0  ...          14       0.0  8.236376\n3      3.0    9.0         1.0  ...          12       0.0  6.459875\n4      3.0    9.0         1.0  ...           7       0.0  1.258493\n5      3.0    9.0         1.0  ...          13       0.0  5.511770\n6      3.0    9.0         1.0  ...           3       0.0 -1.883580\n7      3.0    9.0         1.0  ...          12       0.0  6.679502\n8      3.0    9.0         1.0  ...          14       0.0  7.575472\n9      3.0    9.0         1.0  ...          13       0.0  7.578747\n\n[10 rows x 14 columns]"
          },
          "execution_count": 6,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "scoredData = model.transform(testCat)\n",
        "scoredData.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute model metrics against the entire scored dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6317908Z",
              "execution_start_time": "2021-03-15T08:40:57.16361Z",
              "execution_finish_time": "2021-03-15T08:40:59.235026Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   mean_squared_error  root_mean_squared_error       R^2  mean_absolute_error\n0         1108.469661                33.293688  0.042336            17.477483"
          },
          "execution_count": 7,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputeModelStatistics\n",
        "metrics = ComputeModelStatistics().transform(scoredData)\n",
        "metrics.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, compute and show statistics on individual predictions in the test\n",
        "dataset, demonstrating the usage of `ComputePerInstanceStatistics`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6346751Z",
              "execution_start_time": "2021-03-15T08:40:59.3656204Z",
              "execution_finish_time": "2021-03-15T08:41:01.4288746Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   ArrDelay    Scores    L1_loss      L2_loss\n0       2.0 -5.271233   7.271233    52.870830\n1      -6.0 -2.190444   3.809556    14.512719\n2     -14.0  5.055870  19.055870   363.126173\n3      -5.0  6.082205  11.082205   122.815261\n4       4.0 -1.326078   5.326078    28.367109\n5      86.0  3.353821  82.646179  6830.390844\n6     -17.0  5.617123  22.617123   511.534256\n7     -13.0  5.835471  18.835471   354.774976\n8     -12.0 -5.826737   6.173263    38.109181\n9     -27.0 -4.678505  22.321495   498.249127"
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputePerInstanceStatistics\n",
        "evalPerInstance = ComputePerInstanceStatistics().transform(scoredData)\n",
        "evalPerInstance.select(\"ArrDelay\", \"Scores\", \"L1_loss\", \"L2_loss\") \\\n",
        "               .limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 41,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:39:29.6365837Z",
              "execution_start_time": "2021-03-15T08:41:01.5255123Z",
              "execution_finish_time": "2021-03-15T08:41:03.5877007Z"
            },
            "text/plain": "StatementMeta(SamplePool, 41, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 9,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}