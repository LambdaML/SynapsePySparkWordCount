{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 203 - Hyperparameter Tuning with MMLSpark\n",
        "\n",
        "We can do distributed randomized grid search hyperparameter tuning with MMLSpark.\n",
        "\n",
        "First, we import the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6535822Z",
              "execution_start_time": "2021-03-15T08:01:57.5779291Z",
              "execution_finish_time": "2021-03-15T08:01:59.647001Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's read the data and split it to tuning and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6548715Z",
              "execution_start_time": "2021-03-15T08:01:59.741759Z",
              "execution_finish_time": "2021-03-15T08:02:10.0824385Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Label  Clump_Thickness  ...  Normal_Nucleoli  Mitoses\n0      0                1  ...                1        1\n1      0                1  ...                1        1\n2      0                1  ...                1        1\n3      0                1  ...                1        1\n4      0                2  ...                1        1\n5      0                3  ...                1        1\n6      0                3  ...                1        1\n7      0                3  ...                1        1\n8      0                3  ...                6        1\n9      0                4  ...                6        1\n\n[10 rows x 10 columns]"
          },
          "execution_count": 2,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "data = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/BreastCancer.parquet\")\n",
        "tune, test = data.randomSplit([0.80, 0.20])\n",
        "tune.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, define the models that wil be tuned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6563183Z",
              "execution_start_time": "2021-03-15T08:02:10.1846784Z",
              "execution_finish_time": "2021-03-15T08:02:12.2587889Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.automl import TuneHyperparameters\n",
        "from mmlspark.train import TrainClassifier\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
        "logReg = LogisticRegression()\n",
        "randForest = RandomForestClassifier()\n",
        "gbt = GBTClassifier()\n",
        "smlmodels = [logReg, randForest, gbt]\n",
        "mmlmodels = [TrainClassifier(model=model, labelCol=\"Label\") for model in smlmodels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can specify the hyperparameters using the HyperparamBuilder.\n",
        "We can add either DiscreteHyperParam or RangeHyperParam hyperparameters.\n",
        "TuneHyperparameters will randomly choose values from a uniform distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6576343Z",
              "execution_start_time": "2021-03-15T08:02:12.378024Z",
              "execution_finish_time": "2021-03-15T08:02:14.446501Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "dict_items([(Param(parent='LogisticRegression_93ca77483e6f', name='regParam', doc='regularization parameter (>= 0).'), (LogisticRegression_93ca77483e6f, <mmlspark.automl.HyperparamBuilder.RangeHyperParam object at 0x7f816b5b3780>)), (Param(parent='RandomForestClassifier_f25f794c99fc', name='numTrees', doc='Number of trees to train (>= 1).'), (RandomForestClassifier_f25f794c99fc, <mmlspark.automl.HyperparamBuilder.DiscreteHyperParam object at 0x7f816b5a6f28>)), (Param(parent='RandomForestClassifier_f25f794c99fc', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), (RandomForestClassifier_f25f794c99fc, <mmlspark.automl.HyperparamBuilder.DiscreteHyperParam object at 0x7f816b5b37b8>)), (Param(parent='GBTClassifier_a66ae16ec1d2', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'), (GBTClassifier_a66ae16ec1d2, <mmlspark.automl.HyperparamBuilder.RangeHyperParam object at 0x7f816b5b3400>)), (Param(parent='GBTClassifier_a66ae16ec1d2', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), (GBTClassifier_a66ae16ec1d2, <mmlspark.automl.HyperparamBuilder.DiscreteHyperParam object at 0x7f816b5b32e8>))])"
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.automl import *\n",
        "\n",
        "paramBuilder = \\\n",
        "  HyperparamBuilder() \\\n",
        "    .addHyperparam(logReg, logReg.regParam, RangeHyperParam(0.1, 0.3)) \\\n",
        "    .addHyperparam(randForest, randForest.numTrees, DiscreteHyperParam([5,10])) \\\n",
        "    .addHyperparam(randForest, randForest.maxDepth, DiscreteHyperParam([3,5])) \\\n",
        "    .addHyperparam(gbt, gbt.maxBins, RangeHyperParam(8,16)) \\\n",
        "    .addHyperparam(gbt, gbt.maxDepth, DiscreteHyperParam([3,5]))\n",
        "searchSpace = paramBuilder.build()\n",
        "# The search space is a list of params to tuples of estimator and hyperparam\n",
        "print(searchSpace)\n",
        "randomSpace = RandomSpace(searchSpace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, run TuneHyperparameters to get the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6592154Z",
              "execution_start_time": "2021-03-15T08:02:14.5421168Z",
              "execution_finish_time": "2021-03-15T08:03:25.2713132Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 5,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "bestModel = TuneHyperparameters(\n",
        "              evaluationMetric=\"accuracy\", models=mmlmodels, numFolds=2,\n",
        "              numRuns=len(mmlmodels) * 2, parallelism=1,\n",
        "              paramSpace=randomSpace.space(), seed=0).fit(tune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can view the best model's parameters and retrieve the underlying best model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.661202Z",
              "execution_start_time": "2021-03-15T08:03:25.3846128Z",
              "execution_finish_time": "2021-03-15T08:03:27.4523969Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "cacheNodeIds: false, checkpointInterval: 10, featureSubsetStrategy: auto, featuresCol: TrainClassifier_e1e873f4db55_features, impurity: gini, labelCol: Label, maxBins: 32, maxDepth: 5, maxMemoryInMB: 256, minInfoGain: 0.0, minInstancesPerNode: 1, numTrees: 10, predictionCol: prediction, probabilityCol: probability, rawPredictionCol: rawPrediction, seed: -5387697053847413545, subsamplingRate: 1.0\nTrainClassifier_0b104efd2b1e"
          },
          "execution_count": 6,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "print(bestModel.getBestModelInfo())\n",
        "print(bestModel.getBestModel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can score against the test set and view metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6629998Z",
              "execution_start_time": "2021-03-15T08:03:27.5493529Z",
              "execution_finish_time": "2021-03-15T08:03:31.6994133Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "  evaluation_type  ...       AUC\n0  Classification  ...  0.986696\n\n[1 rows x 6 columns]\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2110: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  Unsupported type in conversion to Arrow: MatrixUDT\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n  warnings.warn(msg)"
          },
          "execution_count": 7,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputeModelStatistics\n",
        "prediction = bestModel.transform(test)\n",
        "metrics = ComputeModelStatistics().transform(prediction)\n",
        "metrics.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 35,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T08:01:28.6657212Z",
              "execution_start_time": "2021-03-15T08:03:31.7913814Z",
              "execution_finish_time": "2021-03-15T08:03:50.3980066Z"
            },
            "text/plain": "StatementMeta(SamplePool, 35, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}