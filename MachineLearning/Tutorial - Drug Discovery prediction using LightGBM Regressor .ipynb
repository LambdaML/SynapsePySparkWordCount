{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quantile Regression for Drug Discovery with LightGBM Regressor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction of LightGBM\n",
        "[LightGBM](https://github.com/Microsoft/LightGBM) is an open-source, distributed, high-performance gradient boosting framework with following advantages: \n",
        "-   Composability: LightGBM models can be incorporated into existing\n",
        "    SparkML Pipelines, and used for batch, streaming, and serving\n",
        "    workloads.\n",
        "-   Performance: LightGBM on Spark is 10-30% faster than SparkML on\n",
        "    the Higgs dataset, and achieves a 15% increase in AUC.  [Parallel\n",
        "    experiments](https://github.com/Microsoft/LightGBM/blob/master/docs/Experiments.rst#parallel-experiment)\n",
        "    have verified that LightGBM can achieve a linear speed-up by using\n",
        "    multiple machines for training in specific settings.\n",
        "-   Functionality: LightGBM offers a wide array of [tunable\n",
        "    parameters](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst),\n",
        "    that one can use to customize their decision tree system. LightGBM on\n",
        "    Spark also supports new types of problems such as quantile regression.\n",
        "-   Cross platformï¼šLightGBM on Spark is available on Spark (Scala) and PySpark (Python)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://mmlspark.blob.core.windows.net/graphics/Documentation/drug.png\" width=\"800\" style=\"float: center;\"/>\n",
        "\n",
        "In this example, we use LightGBM quantile regressor on the Triazines dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "triazines = spark.read.format(\"libsvm\").load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/triazines.scale.svmlight\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1008285Z",
              "execution_start_time": "2021-05-14T13:12:24.6664044Z",
              "execution_finish_time": "2021-05-14T13:12:37.0789077Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print some basic info\n",
        "print(\"records read: \" + str(triazines.count()))\n",
        "print(\"Schema: \")\n",
        "triazines.printSchema()\n",
        "triazines.limit(10).toPandas()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1025252Z",
              "execution_start_time": "2021-05-14T13:12:37.20654Z",
              "execution_finish_time": "2021-05-14T13:12:41.3232259Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "records read: 105\n",
            "Schema: \n",
            "root\n",
            " |-- label: double (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n",
            "   label                                           features\n",
            "0  0.809  (-0.6, -0.3325, -0.3325, -1.0, -1.0, -1.0, -1....\n",
            "1  0.602  (-0.6, 0.0, 0.0, -1.0, -0.3325, -1.0, -1.0, 0....\n",
            "2  0.442  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n",
            "3  0.718  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n",
            "4  0.697  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n",
            "5  0.757  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n",
            "6  0.900  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n",
            "7  0.564  (-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n",
            "8  0.772  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n",
            "9  0.801  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n",
            "/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2110: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n",
            "  Unsupported type in conversion to Arrow: VectorUDT\n",
            "Attempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true."
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation of testing and training data sets\r\n",
        "\r\n",
        "Simple split, 85% for training and 15% for testing the model. Playing with this ratio may result in different models."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = triazines.randomSplit([0.85, 0.15], seed=1)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1049979Z",
              "execution_start_time": "2021-05-14T13:12:41.4710796Z",
              "execution_finish_time": "2021-05-14T13:12:43.5314326Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\r\n",
        "Train the quantile regressor on the training data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from mmlspark.lightgbm import LightGBMRegressor\n",
        "model = LightGBMRegressor(objective='quantile',\n",
        "                          alpha=0.2,\n",
        "                          learningRate=0.3,\n",
        "                          numLeaves=31).fit(train)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1065772Z",
              "execution_start_time": "2021-05-14T13:12:43.671828Z",
              "execution_finish_time": "2021-05-14T13:12:48.3184403Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and load LightGBM to a file using the LightGBM native representation\r\n",
        "\r\n",
        "from mmlspark.lightgbm import LightGBMRegressionModel\r\n",
        "model.saveNativeModel(\"/mymodel\")\r\n",
        "model = LightGBMRegressionModel.loadNativeModelFromFile(\"/mymodel\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1086267Z",
              "execution_start_time": "2021-05-14T13:12:48.4582684Z",
              "execution_finish_time": "2021-05-14T13:12:58.7805054Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the feature importances of the trained model\r\n",
        "\r\n",
        "print(model.getFeatureImportances())"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1102876Z",
              "execution_start_time": "2021-05-14T13:12:58.8965404Z",
              "execution_finish_time": "2021-05-14T13:13:00.9677302Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18.0, 4.0, 8.0, 0.0, 16.0, 16.0, 0.0, 3.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 27.0, 27.0, 18.0, 28.0, 28.0, 0.0, 10.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0]"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model performance evaluation\r\n",
        "\r\n",
        "After training the model, we evaluate the performance of the model using the test set."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "scoredData = model.transform(test)\n",
        "scoredData.limit(10).toPandas()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1122738Z",
              "execution_start_time": "2021-05-14T13:13:01.1003231Z",
              "execution_finish_time": "2021-05-14T13:13:07.2969771Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                           features  prediction\n",
            "0  0.258  (-0.2, 0.3325, -0.6675, -1.0, 0.3325, 0.0, -1....    0.414115\n",
            "1  0.427  (-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....    0.539532\n",
            "2  0.550  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....    0.537624\n",
            "3  0.614  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....    0.640256\n",
            "4  0.631  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....    0.422801\n",
            "5  0.637  (-0.2, 0.0, 0.0, -1.0, 0.3325, 0.0, -1.0, 0.0,...    0.521593\n",
            "6  0.641  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....    0.585361\n",
            "7  0.678  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....    0.585361\n",
            "8  0.788  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....    0.726604\n",
            "9  0.801  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....    0.634850"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics using ComputeModelStatistics\n",
        "\n",
        "from mmlspark.train import ComputeModelStatistics\n",
        "metrics = ComputeModelStatistics(evaluationMetric='regression',\n",
        "                                 labelCol='label',\n",
        "                                 scoresCol='prediction') \\\n",
        "            .transform(scoredData)\n",
        "metrics.toPandas()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SampleSpark",
              "session_id": 44,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-05-14T13:09:38.1141126Z",
              "execution_start_time": "2021-05-14T13:13:07.4090286Z",
              "execution_finish_time": "2021-05-14T13:13:09.4747963Z"
            },
            "text/plain": "StatementMeta(SampleSpark, 44, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean_squared_error  root_mean_squared_error       R^2  mean_absolute_error\n",
            "0            0.014862                  0.12191  0.495869             0.107673"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up resources\r\n",
        "To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
        "\r\n",
        "![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\r\n",
        "\r\n",
        "* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
        "* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}