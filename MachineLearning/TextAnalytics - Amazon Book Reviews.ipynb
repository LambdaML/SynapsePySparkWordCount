{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 201 - Engineering Text Features Using `mmlspark` Modules and Spark SQL\n",
        "\n",
        "Again, try to predict Amazon book ratings greater than 3 out of 5, this time using\n",
        "the `TextFeaturizer` module which is a composition of several text analytics APIs that\n",
        "are native to Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0706531Z",
              "execution_start_time": "2021-03-15T09:04:04.9769791Z",
              "execution_finish_time": "2021-03-15T09:04:07.0445742Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0720689Z",
              "execution_start_time": "2021-03-15T09:04:07.1451417Z",
              "execution_finish_time": "2021-03-15T09:04:15.47377Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   rating                                               text\n0       2  Ok~ but I think the Keirsey Temperment Test is...\n1       2  Repellent Sale of Conservativism  The fatalist...\n2       1  I had a bad feeling about this!  And I was rig...\n3       2  Lost Credability, QUICKLY!!  I admit, I haven'...\n4       2  Poorly written  I tried reading this book but ...\n5       2  The book felt more like the author was forced ...\n6       1  The Islamo-Fascists Murderers thank Professor ...\n7       2  Stranded on an Island  I have been a fan of Su...\n8       2  Another self-indulgent Heinlein novel  Heinlei...\n9       2  Beautiful Beginning / Painful (illogical) Endi..."
          },
          "execution_count": 2,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "data = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/BookReviewsFromAmazon10K.parquet\")\n",
        "data.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `TextFeaturizer` to generate our features column.  We remove stop words, and use TF-IDF\n",
        "to generate 2?? sparse features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0735567Z",
              "execution_start_time": "2021-03-15T09:04:15.5689055Z",
              "execution_finish_time": "2021-03-15T09:04:19.7037487Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 3,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.featurize.text import TextFeaturizer\n",
        "textFeaturizer = TextFeaturizer() \\\n",
        "  .setInputCol(\"text\").setOutputCol(\"features\") \\\n",
        "  .setUseStopWordsRemover(True).setUseIDF(True).setMinDocFreq(5).setNumFeatures(1 << 16).fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0749983Z",
              "execution_start_time": "2021-03-15T09:04:19.8026543Z",
              "execution_finish_time": "2021-03-15T09:04:21.8754048Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   rating  ...                                           features\n0       2  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n1       2  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n2       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n3       2  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n4       2  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n\n[5 rows x 3 columns]\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2110: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  Unsupported type in conversion to Arrow: VectorUDT\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n  warnings.warn(msg)"
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "processedData = textFeaturizer.transform(data)\n",
        "processedData.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the label so that we can predict whether the rating is greater than 3 using a binary\n",
        "classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0764373Z",
              "execution_start_time": "2021-03-15T09:04:21.9755513Z",
              "execution_finish_time": "2021-03-15T09:04:24.0373008Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            features  label\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  False\n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  False\n2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  False\n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  False\n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  False"
          },
          "execution_count": 5,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "processedData = processedData.withColumn(\"label\", processedData[\"rating\"] > 3) \\\n",
        "                             .select([\"features\", \"label\"])\n",
        "processedData.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train several Logistic Regression models with different regularizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0779954Z",
              "execution_start_time": "2021-03-15T09:04:24.1364608Z",
              "execution_finish_time": "2021-03-15T09:05:06.0074529Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 6,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "train, test, validation = processedData.randomSplit([0.60, 0.20, 0.20])\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lrHyperParams = [0.05, 0.1, 0.2, 0.4]\n",
        "logisticRegressions = [LogisticRegression(regParam = hyperParam) for hyperParam in lrHyperParams]\n",
        "\n",
        "from mmlspark.train import TrainClassifier\n",
        "lrmodels = [TrainClassifier(model=lrm, labelCol=\"label\").fit(train) for lrm in logisticRegressions]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the model with the best AUC on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0796665Z",
              "execution_start_time": "2021-03-15T09:05:06.1045772Z",
              "execution_finish_time": "2021-03-15T09:05:16.5089018Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "+-------------------+--------------------+\n|false_positive_rate|  true_positive_rate|\n+-------------------+--------------------+\n|                0.0|                 0.0|\n|                0.0|6.253908692933083E-4|\n|                0.0|0.001250781738586...|\n|                0.0|0.001876172607879925|\n|                0.0|0.002501563477173...|\n|                0.0|0.003126954346466...|\n|                0.0| 0.00375234521575985|\n|                0.0|0.004377736085053158|\n|                0.0|0.005003126954346...|\n|                0.0|0.005628517823639775|\n|                0.0|0.006253908692933083|\n|                0.0|0.006879299562226...|\n|                0.0|0.008130081300813009|\n|                0.0|0.008755472170106316|\n|                0.0|0.009380863039399626|\n|                0.0|0.010006253908692933|\n|                0.0|0.010631644777986242|\n|                0.0| 0.01125703564727955|\n|                0.0|0.011882426516572859|\n|                0.0|0.012507817385866166|\n+-------------------+--------------------+\nonly showing top 20 rows\n\n+---------------+--------------------+--------+------------------+------------------+------------------+\n|evaluation_type|    confusion_matrix|accuracy|         precision|            recall|               AUC|\n+---------------+--------------------+--------+------------------+------------------+------------------+\n| Classification|92.0  309.0   \n9....|   0.841|0.8372827804107424|0.9943714821763602|0.8761694887234694|\n+---------------+--------------------+--------+------------------+------------------+------------------+\n\n+--------------------+------------------+--------------------+\n|          model_name|            metric|          parameters|\n+--------------------+------------------+--------------------+\n|TrainClassifier_3...|0.8678616155047028|aggregationDepth:...|\n|TrainClassifier_3...|0.8705971157160258|aggregationDepth:...|\n|TrainClassifier_9...|0.8733123414103893|aggregationDepth:...|\n|TrainClassifier_3...|0.8761694887234696|aggregationDepth:...|\n+--------------------+------------------+--------------------+"
          },
          "execution_count": 7,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.automl import FindBestModel, BestModel\n",
        "bestModel = FindBestModel(evaluationMetric=\"AUC\", models=lrmodels).fit(test)\n",
        "bestModel.getEvaluationResults().show()\n",
        "bestModel.getBestModelMetrics().show()\n",
        "bestModel.getAllModelMetrics().show()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the optimized `ComputeModelStatistics` API to find the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.0815161Z",
              "execution_start_time": "2021-03-15T09:05:16.6104552Z",
              "execution_finish_time": "2021-03-15T09:05:20.7529463Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Best model's accuracy on validation set = 82.62%"
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputeModelStatistics\n",
        "predictions = bestModel.transform(validation)\n",
        "metrics = ComputeModelStatistics().transform(predictions)\n",
        "print(\"Best model's accuracy on validation set = \"\n",
        "      + \"{0:.2f}%\".format(metrics.first()[\"accuracy\"] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SamplePool",
              "session_id": 46,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-03-15T09:03:36.083395Z",
              "execution_start_time": "2021-03-15T09:05:20.8457422Z",
              "execution_finish_time": "2021-03-15T09:05:22.8997558Z"
            },
            "text/plain": "StatementMeta(SamplePool, 46, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "execution_count": 9,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}